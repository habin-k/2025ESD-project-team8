import os
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt
import json
import random
from tqdm.notebook import tqdm  # Colab í™˜ê²½ì—ì„œ tqdm ì‚¬ìš©

# 1. ëª¨ë“  Training í´ë” ë‚´ .npz íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì¬ê·€ íƒìƒ‰)
def load_npz_in_training_folders(root_dir):
    sequences, labels, lengths = [], [], []
    found_files = 0
    
    for subdir, _, files in os.walk(root_dir):
        if 'Training' in subdir.split(os.sep):
            for fname in tqdm(files, desc="ğŸ” Loading npz files", leave=False):
                if fname.endswith(".npz"):
                    npz_path = os.path.join(subdir, fname)
                    
                    try:
                        npz_data = np.load(npz_path, allow_pickle=True)
                        if "pose" in npz_data.files and "label" in npz_data.files:
                            data = npz_data["pose"]
                            label = npz_data["label"]
                            
                            if data.ndim == 3 and data.shape[1:] == (17, 2):
                                data = data.reshape(data.shape[0], -1)
                                zero_mask = (data == 0).all(axis=1)
                                for t in range(1, data.shape[0]):
                                    if zero_mask[t]:
                                        data[t] = data[t-1]

                                sequences.append(torch.tensor(data, dtype=torch.float32))
                                labels.append(torch.tensor(label, dtype=torch.float32))
                                lengths.append(data.shape[0])
                                found_files += 1

                    except Exception as e:
                        print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {npz_path}, ì˜¤ë¥˜: {e}")

    print(f"âœ… ì´ {found_files}ê°œì˜ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    return sequences, labels, lengths

# 2. ê²½ë¡œ ì„¤ì •
fall_dir = "/content/drive/MyDrive/pose_tensor_npz_test/Y/Training"
normal_dir = "/content/drive/MyDrive/pose_tensor_npz_test/N/Training"

fall_seqs, fall_labs, fall_lens = load_npz_in_training_folders(fall_dir)
normal_seqs, normal_labs, normal_lens = load_npz_in_training_folders(normal_dir)

# 3. ë°ì´í„° ê²°í•© ë° ì…”í”Œ
sequences = fall_seqs + normal_seqs
labels = fall_labs + normal_labs
lengths = fall_lens + normal_lens
combined = list(zip(sequences, labels, lengths))
random.shuffle(combined)
sequences, labels, lengths = zip(*combined)

# 4. Dataset ì •ì˜
class FallDataset(Dataset):
    def __init__(self, sequences, labels, lengths):
        self.sequences = sequences
        self.labels = labels
        self.lengths = torch.tensor(lengths, dtype=torch.long)

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return self.sequences[idx], self.labels[idx], self.lengths[idx]

# 5. Collate í•¨ìˆ˜ (íŒ¨ë”©)
def collate_fn(batch):
    sequences, labels, lengths = zip(*batch)
    padded_seq = pad_sequence(sequences, batch_first=True)
    padded_labels = pad_sequence(labels, batch_first=True)
    return padded_seq, padded_labels, torch.tensor(lengths)

# 6. DataLoader ì¤€ë¹„
dataset = FallDataset(sequences, labels, lengths)
loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)

# 7. LSTM ëª¨ë¸ ì •ì˜
class PackedLSTMClassifier(nn.Module):
    def __init__(self, input_size=34, hidden_size=64):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x, lengths):
        packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)
        packed_output, (hn, _) = self.lstm(packed)
        out = self.fc(hn[-1])
        return self.sigmoid(out).squeeze()

# ëª¨ë¸ ì´ˆê¸°í™”
model = PackedLSTMClassifier().cuda()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.BCELoss()
loss_history = []

# ì €ì¥ ê²½ë¡œ ì„¤ì •
save_dir = "/content/drive/MyDrive/pose_tensor_npz_test/"
best_model_path = os.path.join(save_dir, "best_lstm_model.pth")
epoch_model_path = lambda e: os.path.join(save_dir, f"lstm_model_epoch_{e}.pth")

best_f1 = 0  # ìµœê³  ì„±ëŠ¥ ê¸°ë¡ ë³€ìˆ˜

# 8. í•™ìŠµ ë£¨í”„ (tqdm ì§„í–‰ë¥  í‘œì‹œ)
for epoch in range(10):
    all_preds, all_labels = [], []
    model.train()
    
    with tqdm(loader, desc=f"ğŸ”§ Training Epoch {epoch+1}", leave=False) as pbar:
        for x, y, lengths in pbar:
            x, y = x.cuda(), y.cuda()
            pred = model(x, lengths)
            loss = loss_fn(pred, y)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            loss_history.append(loss.item())

            all_preds += (pred > 0.5).int().tolist()
            all_labels += y.int().tolist()
            
            pbar.set_postfix({"Loss": loss.item()})

    # ì •í™•ë„ì™€ F1 ì ìˆ˜ ê³„ì‚°
    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds)
    print(f"âœ… Epoch {epoch+1} | Loss: {loss.item():.4f} | Acc: {acc:.4f} | F1: {f1:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    torch.save(model.state_dict(), epoch_model_path(epoch + 1))
    if f1 > best_f1:
        best_f1 = f1
        torch.save(model.state_dict(), best_model_path)

# í•™ìŠµ ê²°ê³¼ ì €ì¥
results_save_path = os.path.join(save_dir, "training_results.json")
results = {
    "loss_history": loss_history,
    "best_f1_score": best_f1
}

with open(results_save_path, "w") as f:
    json.dump(results, f)

print(f"âœ… í•™ìŠµ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_save_path}")

# ì†ì‹¤ ì‹œê°í™”
plt.plot(loss_history)
plt.title("Training Loss (Frame-based Fall Detection)")
plt.xlabel("Step")
plt.ylabel("Loss")
plt.grid(True)
plt.show()

import os
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt
import random

# 1. 데이터 로딩 함수
def load_all_npy_in_subfolders(root_dir, label):
    sequences, labels, lengths = [], [], []
    for subdir, _, files in os.walk(root_dir):
        for fname in files:
            if fname.endswith(".npy"):
                path = os.path.join(subdir, fname)
                data = np.load(path, allow_pickle=True)
                if data.ndim == 3 and data.shape[1:] == (17, 2):
                    reshaped = data.reshape(data.shape[0], -1)  # (T, 34)
                    sequences.append(torch.tensor(reshaped, dtype=torch.float32))
                    labels.append(label)
                    lengths.append(len(reshaped))
    return sequences, labels, lengths

# 2. 경로 설정
fall_dir = "/content/pose_tensor/Y"  # 낙상 (1)
normal_dir = "/content/pose_tensor/N"  # 정상 (0)

fall_seqs, fall_labs, fall_lens = load_all_npy_in_subfolders(fall_dir, 1)
normal_seqs, normal_labs, normal_lens = load_all_npy_in_subfolders(normal_dir, 0)

# 3. 낙상 24개 중 랜덤 8개만 선택하여 균형 맞춤
selected = random.sample(range(len(fall_seqs)), k=len(normal_seqs))
fall_seqs = [fall_seqs[i] for i in selected]
fall_labs = [fall_labs[i] for i in selected]
fall_lens = [fall_lens[i] for i in selected]

# 4. 합치고 셔플
sequences = fall_seqs + normal_seqs
labels = fall_labs + normal_labs
lengths = fall_lens + normal_lens

combined = list(zip(sequences, labels, lengths))
random.shuffle(combined)
sequences, labels, lengths = zip(*combined)

# 5. Dataset 클래스
class FallDataset(Dataset):
    def __init__(self, sequences, labels, lengths):
        self.sequences = sequences
        self.labels = torch.tensor(labels, dtype=torch.float32)
        self.lengths = torch.tensor(lengths, dtype=torch.long)

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return self.sequences[idx], self.labels[idx], self.lengths[idx]

# 6. Collate 함수
def collate_fn(batch):
    sequences, labels, lengths = zip(*batch)
    padded = pad_sequence(sequences, batch_first=True)
    return padded, torch.tensor(labels), torch.tensor(lengths)

# 7. LSTM 모델 정의
class PackedLSTMClassifier(nn.Module):
    def __init__(self, input_size=34, hidden_size=64):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x, lengths):
        packed = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)
        _, (hn, _) = self.lstm(packed)
        out = self.fc(hn[-1])
        return self.sigmoid(out).squeeze()

# 8. 학습 준비
dataset = FallDataset(sequences, labels, lengths)
loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)

model = PackedLSTMClassifier()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.BCELoss()
loss_history = []

# 9. 학습 루프
for epoch in range(30):
    all_preds, all_labels = [], []
    for x, y, lengths in loader:
        pred = model(x, lengths)
        loss = loss_fn(pred, y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        loss_history.append(loss.item())
        all_preds += (pred > 0.5).int().tolist()
        all_labels += y.int().tolist()
    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds)
    print(f"Epoch {epoch+1} | Loss: {loss.item():.4f} | Acc: {acc:.4f} | F1: {f1:.4f}")

# 10. 시각화
plt.plot(loss_history)
plt.title("Training Loss (Balanced: Fall vs Normal)")
plt.xlabel("Step")
plt.ylabel("Loss")
plt.grid(True)
plt.show()
